{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "outputs": [],
      "source": [
        "import random \n",
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from statistics import median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CcHOsONTt1K_",
        "outputId": "61467b6a-e330-4a59-a6dc-91acef7a8531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc1htEFYuLRj",
        "outputId": "c825a336-23e5-4174-b83f-633b429414ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQle3T_wuOa3",
        "outputId": "71d7383d-7fc6-4cc9-acf1-367fc74ce5d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
              "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
              "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
              "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
              "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes\n",
        "\n",
        "* <font color='red'><b> Note - While selecting the random 60% datapoints from the whole data, make sure that the selected datapoints are all exclusive, repetition is not allowed. </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6rShd89t552"
      },
      "source": [
        "## <font color='red'><b>A few key points</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdgTUXTouHEd"
      },
      "source": [
        "* Remember that the datapoints used for calculating MSE score contain some datapoints that were initially used while training the base learners (the 60% sampling). This makes these datapoints partially seen (i.e. the datapoints used for calculating the MSE score are a mixture of seen and unseen data).\n",
        "Whereas, the datapoints used for calculating OOB score have only the unseen data. This makes these datapoints completely unseen and therefore appropriate for testing the model's performance on unseen data.\n",
        "\n",
        "* Given the information above, if your logic is correct, the calculated MSE score should be less than the OOB score.\n",
        "\n",
        "* The MSE score must lie between 0 and 10.\n",
        "* The OOB score must lie between 10 and 35.\n",
        "\n",
        "* The difference between the left nad right confidence-interval values must not be more than 10. Make sure this is true for both MSE and OOB confidence-interval values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/OfcFrUP.jpg/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ph_6D2SDzz7F"
      },
      "outputs": [],
      "source": [
        "# refer : above suedo code \n",
        "\n",
        "\n",
        "def generating_samples(input_data, target_data): \n",
        "  \n",
        " \n",
        "  # random choice for generating the index without any replacement \n",
        "  # selecting 303 random row indices from the input_data, without replacement\n",
        "  rows_selected = np.random.choice(len(input_data), 303, replace=False)\n",
        "  \n",
        "  # so now will replicate 203 index from above selected rows \n",
        "  # Replacing Rows => Extracting 206 reandom row indices from the abvoe rows_selected\n",
        "  rows_203_extracted_from_rows_selected = np.random.choice(rows_selected, 203, replace=False)\n",
        "  \n",
        "  # Now get 3 to 13 random column indices from input_data\n",
        "  number_of_columns_to_select = random.randint(3, 13)\n",
        "  columns_selected = np.array(random.sample(range(0, 13), number_of_columns_to_select ))\n",
        "  \n",
        "  sample_data = input_data[rows_selected[:, None], columns_selected]\n",
        "  \n",
        "  target_of_sample_data = target_data[rows_selected]\n",
        "  \n",
        "  # Now Replication of Data for 203 data points out of 303 selected points\n",
        "  \n",
        "  replicated_203_sample_data_points = input_data[rows_203_extracted_from_rows_selected[:, None], columns_selected ]\n",
        "  \n",
        "  target_203_replicated_sample_data = target_data[rows_203_extracted_from_rows_selected]\n",
        "  \n",
        "  # now we will concating the selected row and datapoints \n",
        "  \n",
        "  final_sample_data = np.vstack((sample_data, replicated_203_sample_data_points ))\n",
        "  \n",
        "  final_target_data = np.vstack((target_of_sample_data.reshape(-1, 1), target_203_replicated_sample_data.reshape(-1, 1) ))\n",
        "  \n",
        "  return final_sample_data, final_target_data, rows_selected, columns_selected\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivEQFlm7iOg"
      },
      "source": [
        "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AVvuhNzm7uld",
        "outputId": "4fc9c429-9605-4c6f-f9dc-c06262a7944e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of a (506, 10)\n",
            "shape of b (506, 1)\n",
            "shape of c  (303,)\n",
            "shape of d  (10,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "def grader_samples(a,b,c,d):\n",
        "    length = (len(a)==506  and len(b)==506)\n",
        "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
        "    rows_length = (len(c)==303)\n",
        "    column_length= (len(d)>=3)\n",
        "    assert(length and sampled and rows_length and column_length)\n",
        "    return True\n",
        "a,b,c,d = generating_samples(x, y)\n",
        "grader_samples(a,b,c,d)\n",
        "\n",
        "\n",
        " \n",
        "a,b,c,d = generating_samples(x, y)\n",
        "print(\"shape of a\" ,a.shape)\n",
        "print(\"shape of b\" ,b.shape)\n",
        "print(\"shape of c \" ,c.shape)\n",
        "print(\"shape of d \" ,d.shape)\n",
        "grader_samples(a,b,c,d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XXlKWjCcBvTk"
      },
      "outputs": [],
      "source": [
        "# Use generating_samples function to create 30 samples \n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]\n",
        "\n",
        "for i in range (0, 30):\n",
        "  a, b, c, d = generating_samples(x, y)\n",
        "  list_input_data.append(a)\n",
        "  list_output_data.append(b)\n",
        "  list_selected_row.append(c)\n",
        "  list_selected_columns.append(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hCvIq8NuMWOC",
        "outputId": "b99b92b0-b9d3-4c03-ad00-93e452f6fe75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "def grader_30(a):\n",
        "    assert(len(a)==30 and len(a[0])==506)\n",
        "    return True\n",
        "grader_30(list_input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YWQp6tRwMthq"
      },
      "outputs": [],
      "source": [
        "list_of_all_models_decision_tree = []\n",
        "for i in range(0, 30):\n",
        "  model_i = DecisionTreeRegressor(max_depth=None)\n",
        "  model_i.fit(list_input_data[i], list_output_data[i])\n",
        "  list_of_all_models_decision_tree.append(model_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qWhcvMRWRA9b",
        "outputId": "0109e506-cca6-49aa-83b0-5c3c57cacbde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE :  0.39690914031620556\n"
          ]
        }
      ],
      "source": [
        "# ref : https://www.educative.io/answers/calculating-mean-squared-error-in-python\n",
        "# ref : https://stackoverflow.com/questions/39064684/mean-squared-error-in-python\n",
        "\n",
        "\n",
        "array_of_Y = []  # created the empty list \n",
        "\n",
        "for i in range(0, 30):\n",
        "  data_point_i = x[:, list_selected_columns[i]]\n",
        "  target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
        "  array_of_Y.append(target_y_i)\n",
        "  \n",
        "  \n",
        "predicted_array_of_target_y = np.array(array_of_Y)\n",
        "predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
        "\n",
        "# print(predicted_array_of_target_y.shape)\n",
        "\n",
        "# Now to calculate MSE, first calculate the Median of Predicted Y\n",
        "# passing axis=1 will make sure the medians are computed along axis=1\n",
        "median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
        "median_predicted_y.shape\n",
        "\n",
        "print(\"MSE : \", mean_squared_error(y, median_predicted_y ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3GOcFzTqbt"
      },
      "source": [
        "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Fog_6DNdS-h_",
        "outputId": "5a844902-2040-43d8-9719-d3a762eb914c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final_oob_score is  14.462789767461278\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_predicted_oob_median_list = []\n",
        "\n",
        "for i in range(0, 506):  # declared the range of oob from 0 to 506 \n",
        "  indices_for_oob_models = []  # created the empty variable \n",
        "  \n",
        "  # For each of i-th row I shall build a list, of sample size 30\n",
        "  # ONLY condition being that this i-th row should not be part of the list_selected_row[i-th]\n",
        "  # e.g. say for i = 469 and index_oob in below loop is 10 then \n",
        "  # list_selected_row[10] (which is an array of row-numbers) should not contain the 469-th row\n",
        "  for index_oob in range(0, 30):\n",
        "    if i not in list_selected_row[index_oob]:\n",
        "      indices_for_oob_models.append(index_oob)\n",
        "      \n",
        "  y_predicted_oob_list = []\n",
        "  \n",
        "  for oob_model_index in indices_for_oob_models:\n",
        "    model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
        "    \n",
        "    row_oob = x[i]\n",
        "    # print('oob_model_index ', oob_model_index)\n",
        "    \n",
        "    # Now extract ONLY those specific columns/featues that were selected during the bootstrapping\n",
        "    x_oob_data_point = [row_oob[columns] for columns in list_selected_columns[oob_model_index] ]\n",
        "    # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
        "    x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
        "    \n",
        "    y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
        "    y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
        "    # \n",
        "  y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
        "  \n",
        "  y_predicted_median = np.median(y_predicted_oob_list)\n",
        "  y_predicted_oob_median_list.append(y_predicted_median)\n",
        "  \n",
        "\n",
        "  \n",
        "# here we are culculating the oob score from number of rows \n",
        "def calculate_out_of_bag_score(num_rows):  \n",
        "\n",
        "  oob_score = 0  # here we are intiating frm=om zero \n",
        "\n",
        "  for i in range(0, num_rows): # taking range from zero to number of rows \n",
        "    oob_score += ((y[i] - y_predicted_oob_median_list[i] ) ** 2)  # here we are calculating the oob score by incrementing the value \n",
        "\n",
        "\n",
        "  final_oob_score = oob_score/506\n",
        "  return final_oob_score\n",
        "\n",
        "print(\"final_oob_score is \", calculate_out_of_bag_score(506))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ceW5-D88Uswi",
        "outputId": "06258686-d24a-4f20-d7eb-5e7ecba70825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.06095355731225299, 16.54137969367589)\n"
          ]
        }
      ],
      "source": [
        "# Function to build the entire bootstrapping steps that we did above and\n",
        "# Reurning from the function the MSE and oob score\n",
        "def bootstrapping_and_oob(x, y):\n",
        "\n",
        "  # Use generating_samples function to create 30 samples \n",
        "  # store these created samples in a list\n",
        "  list_input_data =[]\n",
        "  list_output_data =[]\n",
        "  list_selected_row= []\n",
        "  list_selected_columns=[]\n",
        "  \n",
        "  for i in range (0, 30):\n",
        "    a, b, c, d = generating_samples(x, y)\n",
        "    list_input_data.append(a)\n",
        "    list_output_data.append(b)\n",
        "    list_selected_row.append(c)\n",
        "    list_selected_columns.append(d)\n",
        "  \n",
        "  # building regression trees\n",
        "  list_of_all_models_decision_tree = []\n",
        "  for i in range(0, 30):\n",
        "    model_i = DecisionTreeRegressor(max_depth=None)\n",
        "    model_i.fit(list_input_data[i], list_output_data[i])\n",
        "    list_of_all_models_decision_tree.append(model_i)\n",
        "  \n",
        "  # calculating MSE\n",
        "  array_of_Y = []\n",
        "\n",
        "  for i in range(0, 30):\n",
        "    data_point_i = x[:, list_selected_columns[i]]\n",
        "    target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
        "    array_of_Y.append(target_y_i)\n",
        "    \n",
        "    \n",
        "  predicted_array_of_target_y = np.array(array_of_Y)\n",
        "  predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
        "\n",
        "  # print(predicted_array_of_target_y.shape)\n",
        "\n",
        "  # Now to calculate MSE, first calculate the Median of Predicted Y\n",
        "  # passing axis=1 will make sure the medians are computed along axis=1\n",
        "  median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
        "  \n",
        "  # And now the final MSE\n",
        "  MSE = mean_squared_error(y, median_predicted_y )\n",
        "  \n",
        "  # here we will calculate the oob median score \n",
        "  y_predicted_oob_median_list = []\n",
        "\n",
        "  for i in range(0, 506):\n",
        "    indices_for_oob_models = []\n",
        "    \n",
        "    # for each row we need to make sample sixe of 30 as per instruction \n",
        "\n",
        "    # ONLY condition being that this ith row should not be part of\n",
        "    # the list_selected_row\n",
        "    for index_oob in range(0, 30):\n",
        "      if i not in list_selected_row[index_oob]:\n",
        "        indices_for_oob_models.append(index_oob)\n",
        "        \n",
        "    y_predicted_oob_list = []\n",
        "    \n",
        "    for oob_model_index in indices_for_oob_models:\n",
        "      model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
        "      \n",
        "      row_oob = x[i]\n",
        "      # print('oob_model_index ', oob_model_index)\n",
        "      \n",
        "      x_oob_data_point = [row_oob[col] for col in list_selected_columns[oob_model_index] ]\n",
        "      # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
        "      x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
        "      \n",
        "      y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
        "      y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
        "      # \n",
        "    y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
        "    \n",
        "    y_predicted_median = np.median(y_predicted_oob_list)\n",
        "    y_predicted_oob_median_list.append(y_predicted_median)\n",
        "    \n",
        "\n",
        "  oob_score = 0\n",
        "\n",
        "  for i in range(0, 506):\n",
        "    #  refer :  oob_score = (oob_score + (y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
        "    \n",
        "    oob_score += (y[i] - y_predicted_oob_median_list[i] ) ** 2\n",
        "\n",
        "  final_oob_score = oob_score/506\n",
        "  \n",
        "  return MSE, final_oob_score\n",
        "\n",
        "print(bootstrapping_and_oob(x, y))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable\n",
        "\n",
        "mse_boston_35_times_arr = []\n",
        "oob_score_boston_35_times_arr = []\n",
        "\n",
        "# Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score\n",
        "for i in range(0, 35):\n",
        "  mse, oob_score = bootstrapping_and_oob(x, y)\n",
        "  mse_boston_35_times_arr.append(mse)\n",
        "  oob_score_boston_35_times_arr.append(oob_score)\n",
        "\n",
        "\n",
        "mse_boston_35_times_arr = np.array(mse_boston_35_times_arr)\n",
        "oob_score_boston_35_times_arr = np.array(oob_score_boston_35_times_arr)\n",
        "\n",
        "confidence_level = 0.95\n",
        "degrees_of_freedom = 34 # sample.size - 1\n",
        "\n",
        "mean_of_sample_mse_35 = np.mean(mse_boston_35_times_arr)\n",
        "standard_error_of_sample_mse_35 = scipy.stats.sem(mse_boston_35_times_arr)\n",
        "\n",
        "\n",
        "# Per document - https://www.kite.com/python/answers/how-to-compute-the-confidence-interval-of-a-sample-statistic-in-python\n",
        "# confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
        "confidence_interval_mse_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_mse_35, standard_error_of_sample_mse_35 )\n",
        "print(\"confidence_interval_mse_35 \", confidence_interval_mse_35)\n",
        "\n",
        "# Now calculate confidence inter for oob score\n",
        "mean_of_sample_oob_score_35 = np.mean(oob_score_boston_35_times_arr)\n",
        "standard_error_of_sample_oob_score_35 = scipy.stats.sem(oob_score_boston_35_times_arr)\n",
        "\n",
        "confidence_interval_oob_score_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_oob_score_35, standard_error_of_sample_oob_score_35 )\n",
        "print(\"confidence_interval_oob_score_35 \", confidence_interval_oob_score_35)"
      ],
      "metadata": {
        "id": "D6XAAfznaVef",
        "outputId": "17b61607-2cc5-41b7-d6b2-c5a82ad9d5a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confidence_interval_mse_35  (0.09020789646549911, 0.15168791935432868)\n",
            "confidence_interval_oob_score_35  (13.039539604393621, 14.451392285356814)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "i_pUlSD-VYD1",
        "outputId": "662c5c8d-8242-4129-cd96-0eafe9e40c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.7"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "def predict_y_given_x_bootstrap(x_query):\n",
        "  y_predicted_array_30_sample = []\n",
        "  \n",
        "  for i in range(0, 30):\n",
        "    model_i = list_of_all_models_decision_tree[i]\n",
        "    # Extract x for ith data point with specific number of featues from list_selected_columns\n",
        "    x_data_point_i = [x_query[column] for column in list_selected_columns[i]]\n",
        "    x_data_point_i = np.array(x_data_point_i).reshape(1, -1)\n",
        "\n",
        "    # here we are predicting the y for quesry point xq from all base_learners \n",
        "    y_predicted_i = model_i.predict(x_data_point_i)\n",
        "    y_predicted_array_30_sample.append(y_predicted_i)\n",
        "    \n",
        "  y_predicted_array_30_sample = np.array(y_predicted_array_30_sample)\n",
        "  y_predicted_median = np.median(y_predicted_array_30_sample)\n",
        "  return y_predicted_median\n",
        "\n",
        "# here from the given set of sample of query print xq\n",
        "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "\n",
        "# here as per instruction predicting the y for given xq \n",
        "y_predicted_for_xq = predict_y_given_x_bootstrap(xq)\n",
        "y_predicted_for_xq    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJHTGEZgWJjR"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUi-0xWOJ9"
      },
      "source": [
        "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 1"
      ],
      "metadata": {
        "id": "PLNnWZxA7dsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) first we sampled the datapoint and features a per instruction  randomly .**\n",
        "\n",
        "**2) after concating of datapoint we calculated the mean sqaured error and MSE we got .04%  between actual error and predicting error .** \n",
        "\n",
        "\n",
        "**3) means our model performing really good not a much big difference between actual and predicted error** \n"
      ],
      "metadata": {
        "id": "CFSPOdrm7em6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TASK 2 "
      ],
      "metadata": {
        "id": "7ng9IU157e-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A): observation \n",
        "**1: the oob score we got 14%**\n",
        "\n",
        "**2: that really god because that's mean 14% dataset we got as validation data .**\n",
        "\n",
        "**3: from these dataset we can conclude that how are model will perform on test data**\n",
        "\n",
        "##(B) : observation \n",
        "\n",
        "**1) final oob score we got 13% with .03% mse score not a big dfference model will perform will good on test data**\n",
        "\n",
        "##(c) : observation \n",
        "\n",
        "**1) mse score on confidence interval of 35  is 0.06 , .16%  difference is less than 10 so output is as expected**\n",
        "\n",
        "**2) both the oob score got 13% and 14% dataset we got for validation perpose to make_sure the performence of test data** "
      ],
      "metadata": {
        "id": "se_sb2p77fJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 3"
      ],
      "metadata": {
        "id": "_HGg0IF37fWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1) the predictedY we got for query point xq is 18.7**\n",
        "\n",
        "**2) 18.7 value we have got for given sample of array of 30 xq datapoints**\n"
      ],
      "metadata": {
        "id": "AUpYeYI27fgW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJyBiFcY8ohr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}